{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83175cdd-df67-4892-89be-f595fff55b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060e30d-8a72-4504-b1a8-87f3e03d98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'E:/BitBot/training_data_sections/'\n",
    "models_path = 'E:/BitBot/models'\n",
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc001d-1f97-4444-b17a-35637570ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols, timestamps_train, timestamps_valid = set(), set(), set()\n",
    "for filename in os.listdir(training_path):\n",
    "    symbols.add(filename[11:-11].replace('.csv', ''))\n",
    "    if 'train' in filename:\n",
    "        timestamps_train.add(filename[:10])\n",
    "    elif 'valid' in filename:\n",
    "        timestamps_valid.add(filename[:10])\n",
    "\n",
    "symbols = list(symbols)\n",
    "timestamps_train, timestamps_valid = sorted(list(timestamps_train)), sorted(list(timestamps_valid))\n",
    "timestamps = {}\n",
    "for timestamp_train, timestamp_valid in zip(timestamps_train, timestamps_valid):\n",
    "    timestamps[timestamp_train] = timestamp_valid\n",
    "\n",
    "print(symbols)\n",
    "print(list(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756051f-a308-47d2-8eea-03b46a0be8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(timestamp_train, timestamp_valid):\n",
    "    dfs_train, dfs_valid = [], []\n",
    "    for filename in os.listdir(training_path):\n",
    "        if timestamp_train in filename and 'train' in filename:\n",
    "            df = pd.read_csv(training_path + filename)\n",
    "            dfs_train.append(df)\n",
    "        elif timestamp_valid in filename and 'valid' in filename:\n",
    "            df = pd.read_csv(training_path + filename)\n",
    "            dfs_valid.append(df)\n",
    "    dfs_train, dfs_valid = pd.concat(dfs_train), pd.concat(dfs_valid)\n",
    "    return dfs_train, dfs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce02840-3556-4fc4-8cd2-542db516c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(dfs_train, dfs_valid):\n",
    "    len_train, len_valid = dfs_train.shape[0], dfs_valid.shape[0]\n",
    "    splits = [\n",
    "        list(range(0, len_train)),\n",
    "        list(range(len_train, len_train + len_valid))\n",
    "    ]\n",
    "    df = pd.concat([dfs_train, dfs_valid])\n",
    "    return df, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3ee39-1b66-4551-9e02-f832eadcedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(df):\n",
    "    y_count = 7\n",
    "    cat_names = list(df.columns)[-len(symbols)-y_count:-y_count]\n",
    "    cont_names = list(df.columns)[1:-len(symbols)-y_count]\n",
    "    y_names = list(df.columns)[-y_count:]        \n",
    "    to = TabularPandas(df, procs=[Categorify], cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)\n",
    "    dataloader = to.dataloaders(bs=2**10)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2128a8-8a06-41f0-a6c2-05141e496288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    learn = tabular_learner(dataloader, metrics=rmse)\n",
    "    learn.fit_one_cycle(4, lr_max=5e-5)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f54c5-8912-44e4-869e-268f29f1073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(timestamp, df, learn):\n",
    "    dl_train = DataLoader(dataset=df.iloc[splits[0]])\n",
    "    df_val = DataLoader(dataset=df.iloc[splits[1]])\n",
    "    df_train, df_val = df.iloc[splits[0]], df.iloc[splits[1]]\n",
    "    dl_train = learn.dls.test_dl(df_train)\n",
    "    dl_val = learn.dls.test_dl(df_val)\n",
    "    pred_train, gt_train = learn.get_preds(dl=dl_train)\n",
    "    pred_val, gt_val = learn.get_preds(dl=dl_val)\n",
    "    with open(f'preds_{timestamp}.pickle', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'pred_train': pred_train.squeeze(),\n",
    "            'gt_train': gt_train.squeeze(),\n",
    "            'pred_val': pred_val.squeeze(),\n",
    "            'gt_val': gt_val.squeeze()\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225ad7b-45db-46cb-8bcc-5c546ba02d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started = False\n",
    "for timestamp_train in timestamps:\n",
    "    #if timestamp_train == \"2020-07-06\":\n",
    "    #    started = True\n",
    "    #if not started:\n",
    "    #    continue\n",
    "    \n",
    "    timestamp_valid = timestamps[timestamp_train]\n",
    "    print(f\"{timestamp_train} - {timestamp_valid}\")\n",
    "    dfs_train, dfs_valid = read_training_data(timestamp_train, timestamp_valid)\n",
    "    df, splits = make_splits(dfs_train, dfs_valid)\n",
    "    dataloader = make_dataloader(df)\n",
    "    learn = train(dataloader)\n",
    "    make_predictions(timestamp_train, df, learn)\n",
    "    learn.export(models_path + f\"/model_{timestamp_train}_{timestamp_valid}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b8c6d-5b7a-43fe-9d2b-07d49bb7e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebee0ff-5470-44e5-b9ba-188c449842e9",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"E:/BitBot/training_data_sections/2021-07-21_XRPUSDT_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e8feb-0b5e-4d9d-85dc-faa47c8cceb0",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540cf6d-dca5-4425-b6b1-e2682332e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f1336-0067-4139-8720-ddfb3536bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/BitBot/training_data_sections/2021-07-21_XRPUSDT_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af308f-f2b8-4f64-b3de-2f7ff2d4b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff2803-f04b-4eb1-99d5-0cb59bb7fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ed9bf-59da-499c-8c19-2413ad3d8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68834f43-3259-4b17-a625-9878094817ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
